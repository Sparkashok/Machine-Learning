{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR0i/L7b8SdfFdj0j9Webt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sparkashok/Machine-Learning/blob/main/ML_DecisionTree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XQLVvk627Pj",
        "outputId": "c94923b2-e431-44cd-d3f9-a7ca99853806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from graphviz import Digraph\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "def entropy(y):\n",
        "    values, counts = np.unique(y, return_counts=True)\n",
        "    probabilities = counts / counts.sum()\n",
        "    return -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "def best_split(X, y):\n",
        "    best_gain = -1\n",
        "    best_feature = None\n",
        "    best_threshold = None\n",
        "    for feature in range(X.shape[1]):\n",
        "        thresholds = np.unique(X[:, feature])\n",
        "        for threshold in thresholds:\n",
        "            left_indices = X[:, feature] <= threshold\n",
        "            right_indices = X[:, feature] > threshold\n",
        "            if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
        "                continue\n",
        "            left_entropy = entropy(y[left_indices])\n",
        "            right_entropy = entropy(y[right_indices])\n",
        "            gain = entropy(y) - (np.sum(left_indices) / len(y) * left_entropy + np.sum(right_indices) / len(y) * right_entropy)\n",
        "            if gain > best_gain:\n",
        "                best_gain = gain\n",
        "                best_feature = feature\n",
        "                best_threshold = threshold\n",
        "    return best_feature, best_threshold\n",
        "\n",
        "def build_tree(X, y):\n",
        "    if len(np.unique(y)) == 1:\n",
        "        return Node(value=y[0])\n",
        "    feature, threshold = best_split(X, y)\n",
        "    if feature is None:\n",
        "        return Node(value=np.bincount(y).argmax())\n",
        "    left_indices = X[:, feature] <= threshold\n",
        "    right_indices = X[:, feature] > threshold\n",
        "    left_subtree = build_tree(X[left_indices], y[left_indices])\n",
        "    right_subtree = build_tree(X[right_indices], y[right_indices])\n",
        "    return Node(feature, threshold, left_subtree, right_subtree)\n",
        "\n",
        "def predict(node, x):\n",
        "    if node.value is not None:\n",
        "        return node.value\n",
        "    if x[node.feature] <= node.threshold:\n",
        "        return predict(node.left, x)\n",
        "    else:\n",
        "        return predict(node.right, x)\n",
        "\n",
        "def predict_all(tree, X):\n",
        "    return np.array([predict(tree, x) for x in X])\n",
        "\n",
        "def visualize_tree(node, dot=None, parent=None, edge_label=None):\n",
        "    if dot is None:\n",
        "        dot = Digraph()\n",
        "    if node.value is not None:\n",
        "        dot.node(str(id(node)), f\"Class: {node.value}\")\n",
        "    else:\n",
        "        dot.node(str(id(node)), f\"Feature {node.feature}\\n<= {node.threshold}\")\n",
        "    if parent is not None:\n",
        "        dot.edge(str(id(parent)), str(id(node)), label=edge_label)\n",
        "    if node.left:\n",
        "        visualize_tree(node.left, dot, node, \"Yes\")\n",
        "    if node.right:\n",
        "        visualize_tree(node.right, dot, node, \"No\")\n",
        "    return dot\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and visualize the tree\n",
        "tree = build_tree(X_train, y_train)\n",
        "dot = visualize_tree(tree)\n",
        "dot.render(\"decision_tree\", format=\"png\", cleanup=False)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = predict_all(tree, X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ]
    }
  ]
}