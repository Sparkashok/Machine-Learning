{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sparkashok/Machine-Learning/blob/main/ML_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NNkX_7T92BB",
        "outputId": "6cce860d-2c3f-4371-9137-2f8225e8d364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Descent Coefficients:\n",
            "b0 = 0.3724776192, b1 = 1.3783441663999998\n",
            "Absolute errors in each iteration:\n",
            "[30, 22.8, 17.304, 13.1088, 9.9066048]\n",
            "Analytical Solution Coefficients:\n",
            "b0 = 0.0, b1 = 2.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def gradient_descent(x, y, learning_rate=0.01, iterations=5):\n",
        "    n = len(x)\n",
        "    b0, b1 = 0, 0  # Initialize coefficients\n",
        "    errors = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        y_pred = b0 + b1 * x\n",
        "        error = y - y_pred\n",
        "        total_abs_error = np.sum(np.abs(error))\n",
        "        errors.append(total_abs_error)\n",
        "\n",
        "        # Gradient updates\n",
        "        b0 -= learning_rate * (-2 / n) * np.sum(error)\n",
        "        b1 -= learning_rate * (-2 / n) * np.sum(error * x)\n",
        "\n",
        "    return b0, b1, errors\n",
        "\n",
        "def analytical_solution(x, y):\n",
        "    x_mean, y_mean = np.mean(x), np.mean(y)\n",
        "    b1 = np.sum((x - x_mean) * (y - y_mean)) / np.sum((x - x_mean) ** 2)\n",
        "    b0 = y_mean - b1 * x_mean\n",
        "    return b0, b1\n",
        "\n",
        "# Sample data\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2, 4, 6, 8, 10])\n",
        "\n",
        "# Gradient Descent Method\n",
        "b0_gd, b1_gd, errors = gradient_descent(x, y)\n",
        "print(\"Gradient Descent Coefficients:\")\n",
        "print(f\"b0 = {b0_gd}, b1 = {b1_gd}\")\n",
        "print(\"Absolute errors in each iteration:\")\n",
        "print(errors)\n",
        "\n",
        "# Analytical Method\n",
        "b0_ana, b1_ana = analytical_solution(x, y)\n",
        "print(\"Analytical Solution Coefficients:\")\n",
        "print(f\"b0 = {b0_ana}, b1 = {b1_ana}\")\n",
        "\n",
        "# Prediction\n",
        "x_new = float(input(\"Enter new x value to predict y: \"))\n",
        "y_new_gd = b0_gd + b1_gd * x_new\n",
        "y_new_ana = b0_ana + b1_ana * x_new\n",
        "print(f\"Predicted y (Gradient Descent) = {y_new_gd}\")\n",
        "print(f\"Predicted y (Analytical Solution) = {y_new_ana}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvZk5OTMvZAwkhP2usqswi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}